---
title: "P8105 Data Science I Homework 4"
author: Olivia Wang (hw2852)
output: github_document
date: "2022-11-16"
---

In preparation for the problems below, we will load the following libraries: 

```{r load_libraries}
library(tidyverse)
library(readxl)
library(dplyr)
```

# Problem 1



# Problem 2

Let us begin by importing the CSV file containing _Washington Post's_ homicide data downloaded from GitHub, and applying the `clean_names` function. We can then apply the `skim` function to generate a brief data summary. 

```{r}
homicide_data = 
  read_csv("./homicide-data.csv") %>% 
  janitor::clean_names()

skimr::skim(homicide_data)
```

The _Washington Post's_ raw homicide data contains __`r nrow(homicide_data)` rows__ and __`r ncol(homicide_data)` columns__. Each row corresponds to one homicide case, and the following information regarding the homicide are found in each column:

* Case ID code
* Reported date
* Victim identifiers (name, age, race and sex)
* Location details (state, city, latitude and longitude)
* Disposition

Based on the output generated above, we can see that there are no missing values for all variables except for `latitude` and `longitude`. The `latitude` variable has __`r sum(is.na(homicide_data$lat))` missing values__ and the `longitude` variable has __`r sum(is.na(homicide_data$lon))` missing values__. 

## 2.1 City-Level Summaries of Homicide Data

#### _Total Homicides per City_

In the following code chunk, we create a new `city_state` variable (e.g. "Baltimore, MD") by joining the existing city and state variables using the `paste` command. Since each row represents a unique homicide case, we can determine the total number of homicides by counting the number of observations per city-state pair. We will save the output as a new data frame, to be used in further analysis. 

```{r}
homicide_data = homicide_data %>% 
  mutate(city_state = as.character(paste(city, state, sep = ", ")))

total_homicides =
  homicide_data %>% 
  group_by(city_state) %>% 
  summarize(n_obs = n()) %>% 
  arrange(desc(n_obs))
  
knitr::kable(total_homicides, col.names = c('City, State', 'Total Homicides (n)'))
```

The output above reveals a something unexpected in these data: the homicide data collected by _Washington Post_ actually contains data from __51__ distinct cities, as opposed to the 50 originally indicated. Further analysis of the data reveals that this discrepancy likely arose due to the fact that there are two cities named Tulsa in different states: one in Alabama and another in Oklahoma. Although the data from Tulsa, AL seems to suggest that it may be a typographical error (i.e., Tulsa, AL was supposed to be entered as Tulsa, OK) since it reports to have one single homicide over a decade, it is important for data analysts to not make any assumptions about the data. Since the raw data indicates that Tulsa, AL only reported one single homicide, and therefore has minimal impact on our overall sample size, the data from Tulsa, AL will be removed for further analysis. 

```{r}
total_homicides = total_homicides %>% 
  filter(n_obs > 1)
```


#### _Total Unsolved Homicides per City_

To determine the total number of unsolved homicides per city, we can generate a new binary `unsolved_homicide` variable, which will take on a value of 1 if the homicide is unsolved (i.e., disposition = "Closed without arrest" or "Open/No arrest") and 0 if the homicide is solved (i.e., disposition = "Closed by arrest"). We will save the output as a new data frame, to be used in further analysis. 

```{r}
homicide_data = homicide_data %>% 
  mutate(unsolved_homicide = ifelse(disposition == "Closed by arrest", 0, 1))

unsolved_homicides =
  homicide_data %>% 
  group_by(city_state) %>%
  filter(unsolved_homicide == 1) %>% 
  summarize(n_obs = n()) 

knitr::kable(unsolved_homicides, col.names = c('City, State', 'Unsolved Homicides (n)'))
```

## 2.2 City-Level Homicide Porportion Estimates & 95% CIs

#### _Proportion of Unsolved Homicides in Baltimore, MD_

Below we use the `prop.test` function to estimate the proportion of homicides that are unsolved in Baltimore, MD. The arguments for the `prop.test` function, x and n, were determined using the outputs from Problem 2.1. Argument x, a vector of counts of successes, is the number of unsolved homicides in Baltimore, MD, and n, a vector of counts of trials, is the total number of homicides in Baltimore, MD.

The output generated from the `prop.test` function is then saved as an R object. The `broom::tidy()` function was applied to tidy these data, and finally the proportion estimate and the 95% confidence interval values were pulled. 

```{r}
homicide_data %>% 
  filter(city_state == "Baltimore, MD")

prop_test_homicide_baltimore = prop.test(x = 1825, n = 2827, conf.level = 0.95) 

prop_test_homicide_baltimore %>%
  broom::tidy() %>%
  select(estimate, starts_with("conf")) %>% 
  knitr::kable(col.names = c('Proportion Estimate', 'Lower 95% CI Limit', 'Upper 95% CI Limit'))
```

#### _Proportion of Unsolved Homicides in All Cities_

We will now apply the `prop.test` function to all cities in the data set. This process involves first creating a new `homicide_data_to_prop_test` function, which applies the `prop.test` function to any inputs. The `inner_join` function is applied to merge the two data frames containing city-level total and unsolved homicide counts to yield one data frame with both pieces of information. The city-level homicide data will then be nested using the `nest` function to generate list columns for city-level homicide counts, and the `homicide_data_to_prop_test` function will be mapped to each tibble using `purrr::map`. 

```{r}
homicide_data_to_prop_test = function(homicide_data) {
  prop.test(x = homicide_data$n_obs.y, n = homicide_data$n_obs.x, conf.level = 0.95) %>%
    broom::tidy() %>% 
    select(estimate, starts_with("conf"))
}

homicide_data_analysis = inner_join(total_homicides, unsolved_homicides, by = "city_state") %>%
  nest(data = n_obs.x:n_obs.y) %>%
  mutate(data = purrr::map(data, ~ homicide_data_to_prop_test(.x))) %>%
  unnest(cols = data)

knitr::kable(homicide_data_analysis, col.names = c('City, State', 'Proportion Estimate', 'Lower 95% CI Limit', 'Upper 95% CI Limit'))
```

#### _Plotting City-Level Homicides Proportion Estimates & 95% CIs_

using the generated output from the analysis above, we can plot the city-level proportion estimates of unsolved homicides using `ggplot`. In addition to plotting the proportion estimates using `geom_point`, the plot below also depicts the 95% confidence intervals associated with each estimate, which were applied using `geom_errorbar`. Cities are ordered in increasing proportion estimates of unsolved homicides. 

```{r}
homicide_data_analysis %>% 
  ggplot(aes(x = reorder(city_state, estimate), y = estimate, color = city_state)) + 
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(
    title = "City-Level Proportion Estimates for Unsolved Homicides", 
    x = "City, State", 
    y = "Proportion Estimate") + 
  theme(
    axis.text.x = element_text(angle = 70, hjust = 1), 
    legend.position = "none")
```

# Problem 3

## 3.1 Simulation Setup

#### _Setting Model Design Elements_

To 

```{r}
ttest_sim = function(n = 30, mu, sigma = 5) {
  tibble(x = rnorm(n = n, mean = mu, sd = sigma)) %>%
    t.test() %>% 
    broom::tidy() %>% 
    select(estimate, p.value)
}
output =
  data.frame(mu = 0:6, data = 0:6) %>%
    mutate(data = purrr::map(.x = data, ~ rerun(5000, ttest_sim(mu = .x)))) %>%
    unnest() %>%
    unnest()

output
```

```{r}
output %>%
  mutate(is_rejected = ifelse(p.value < 0.05, 1, 0)) %>%
  group_by(mu) %>%
  summarize(power = mean(is_rejected)) %>%
  ggplot(aes(x = mu, y = power)) +
  geom_point()
```
```{r}
output %>%
  group_by(mu) %>%
  summarize(mean_mu_hat = mean(estimate), mean_rejected_mu_hat = mean(estimate[p.value < 0.05])) %>%
  ggplot() +
  geom_point(aes(x = mu, y = mean_mu_hat, colour = 'red')) +
  geom_point(aes(x = mu, y = mean_rejected_mu_hat, color = 'green'))
```








